{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
    "### Due: October 10 at 11:59pm\n",
    "\n",
    "### Name: Romil Dhagat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "33f86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yellowbrick\n",
    "from yellowbrick.datasets import load_spam, load_concrete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of X <class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X (4600, 57)\n",
      "Size of X 262200\n",
      "Type of y <class 'pandas.core.series.Series'>\n",
      "Shape of y (4600,)\n",
      "Size of y 4600\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "X,y = load_spam()\n",
    "# TO DO: Print size and type of X and y\n",
    "print(\"Type of X\",type(X))\n",
    "print(\"Shape of X\",X.shape)\n",
    "print(\"Size of X\",X.size)\n",
    "print(\"Type of y\",type(y))\n",
    "print(\"Shape of y\",y.shape)\n",
    "print(\"Size of y\",y.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "missing = np.isnan(X).sum().sum()\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "# Create X_small and y_small \n",
    "X_waste,X_small,y_waste,y_small = train_test_split(X,y,test_size = 0.05, random_state=0)\n",
    "X_small_train,X_small_test,y_small_train,y_small_test = train_test_split(X_small,y_small,random_state=0)\n",
    "# Creating X and y test train split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)\n",
    "# Creating the two column test train split\n",
    "X_col = X.iloc[:,0:2]\n",
    "X_col_train,X_col_test,y_col_train,y_col_test = train_test_split(X_col,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a6feb0",
   "metadata": {},
   "source": [
    "### Step 3: Implementing Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model0 = LogisticRegression(max_iter=2000)\n",
    "model1 = LogisticRegression(max_iter=2000)\n",
    "model2 = LogisticRegression(max_iter=2000)\n",
    "\n",
    "# Creating ML Logistic Regression prediction for X and y\n",
    "model0.fit(X_train,y_train)\n",
    "y_pred = model0.predict(X_test)\n",
    "y_train_pred = model0.predict(X_train)\n",
    "\n",
    "# Creating ML Logistic Regression prediction for X_small and y_small\n",
    "model1.fit(X_small_train,y_small_train)\n",
    "y_small_pred = model1.predict(X_small_test)\n",
    "y_small_train_pred = model1.predict(X_small_train)\n",
    "\n",
    "# Creating ML Logistic Regression prediction for X_col and y_col\n",
    "model2.fit(X_col_train,y_col_train)\n",
    "y_col_pred = model2.predict(X_col_test)\n",
    "y_col_train_pred = model2.predict(X_col_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc53d26",
   "metadata": {},
   "source": [
    "### Step 4: Validating dataset predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1c7bcb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Using Accuracy scores:\n",
      "\n",
      "The full data set (X and y) has the following results: \n",
      "Training score: 0.928\n",
      "Validation score: 0.938\n",
      "\n",
      "The small data set (X_small and y_small) has the following results: \n",
      "Training score: 0.965\n",
      "Precision score: 0.793\n",
      "\n",
      "The two column data set (X_col and y_col) has the following results: \n",
      "Training score: 0.619\n",
      "Precision score: 0.595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Validating X and y dataset predictions\n",
    "# X_y_scores = cross_validate(model0,X_train,y_train,cv=5,return_train_score=True)\n",
    "# X_y_train_score = X_y_scores['train_score'].mean()\n",
    "# X_y_val_score = X_y_scores['test_score'].mean()\n",
    "X_y_train_acc_score = accuracy_score(y_train,y_train_pred)\n",
    "X_y_val_acc_score = accuracy_score(y_test,y_pred)\n",
    "\n",
    "# Validating X_small and y_small dataset predictions \n",
    "# X_y_small_scores = cross_validate(model1,X_small_train,y_small_train,cv=5,return_train_score=True)\n",
    "# X_y_small_train_score = X_y_small_scores['train_score'].mean()\n",
    "# X_y_small_val_score = X_y_small_scores['test_score'].mean()\n",
    "X_y_small_train_acc_score = accuracy_score(y_small_train,y_small_train_pred)\n",
    "X_y_small_val_acc_score = accuracy_score(y_small_test,y_small_pred)\n",
    "\n",
    "# Validating the first two columns of X and y dataset predictions \n",
    "# col_scores = cross_validate(model2,X_col_train,y_col_train,cv=5,return_train_score=True)\n",
    "# col_train_score = X_y_scores['train_score'].mean()\n",
    "# col_val_score = X_y_scores['test_score'].mean()\n",
    "col_train_acc_score = accuracy_score(y_col_train,y_col_train_pred)\n",
    "col_val_acc_score = accuracy_score(y_col_test,y_col_pred)\n",
    "\n",
    "print(\"\\n Using Accuracy scores:\\n\")\n",
    "print(\"The full data set (X and y) has the following results: \")\n",
    "print(\"Training score: {:.3f}\".format(X_y_train_acc_score))\n",
    "print(\"Validation score: {:.3f}\".format( X_y_val_acc_score))\n",
    "\n",
    "print(\"\\nThe small data set (X_small and y_small) has the following results: \")\n",
    "print(\"Training score: {:.3f}\".format(X_y_small_train_acc_score))\n",
    "print(\"Precision score: {:.3f}\".format( X_y_small_val_acc_score))\n",
    "\n",
    "\n",
    "print(\"\\nThe two column data set (X_col and y_col) has the following results: \")\n",
    "print(\"Training score: {:.3f}\".format(col_train_acc_score))\n",
    "print(\"Precision score: {:.3f}\".format(col_val_acc_score))\n",
    "\n",
    "\n",
    "# print(\"\\n Using Cross-Validation: (I initially used Cross-Validation until I saw that I wasn't supposed to, so disregard as needed)\\n\")\n",
    "# print(\"The full data set (X and y) has the following coss-validation results: \")\n",
    "# print(\"Training score: {:.3f}\".format(X_y_train_score))\n",
    "# print(\"Validation score: {:.3f}\".format( X_y_val_score))\n",
    "\n",
    "# print(\"\\nThe small data set (X_small and y_small) has the following cross-validation results: \")\n",
    "# print(\"Training score: {:.3f}\".format(X_y_small_train_score))\n",
    "# print(\"Precision score: {:.3f}\".format( X_y_small_val_score))\n",
    "\n",
    "\n",
    "# print(\"\\nThe two column data set (X_col and y_col) has the following cross-validation results: \")\n",
    "# print(\"Training score: {:.3f}\".format(col_train_score))\n",
    "# print(\"Precision score: {:.3f}\".format(col_val_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5135e20d",
   "metadata": {},
   "source": [
    "### Step 5: Visual Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "55a8473e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Data Size  Training Accuracy  Validation Accuracy\n",
      "0     262200           0.928406             0.938261\n",
      "1      13110           0.965116             0.793103\n",
      "2       9200           0.618841             0.594783\n"
     ]
    }
   ],
   "source": [
    "### 1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "### 2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "### 3. Print `results`\n",
    "\n",
    "results = pd.DataFrame(columns=['Data Size', 'Training Accuracy', 'Validation Accuracy'])\n",
    "\n",
    "X_y_row = {'Data Size':X.size,'Training Accuracy':X_y_train_acc_score,'Validation Accuracy':X_y_val_acc_score}\n",
    "X_y_small_row = {'Data Size':X_small.size,'Training Accuracy':X_y_small_train_acc_score,'Validation Accuracy':X_y_small_val_acc_score}\n",
    "col_row = {'Data Size':X_col.size,'Training Accuracy':col_train_acc_score,'Validation Accuracy':col_val_acc_score}\n",
    "\n",
    "results.loc[0] = X_y_row\n",
    "results.loc[1] = X_y_small_row\n",
    "results.loc[2] = col_row\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "\n",
    "1. \n",
    "The amount of data used has high impact on the accuracy and the variance. As seen from the results dataframe, the largest data set has a variance between the Training Accuracy and the Validation Accuracy of 1% meaning this model has high accuracy and low variance but high bias, and could be an indication of underfitting. Once the amount of data is lowered, to 5% of the full data, the training accuracy increases however the validation accuracy drops signinficantly, causing a 17.2% variance between the two, meaning smaller data created high variance and low bias and could be an indication for overfitting. Finally dropping the columns, signifcantly reduces the accuracy of both the training and validation sets, however the varaince is around 1.4% which means the model retains a low variance, and high bias. \n",
    "\n",
    "2. \n",
    "A false positive is a non-spam email being catergorized as spam and a false negative is a spam email being catergorized as non-spam. A false postive is much worse becuase you could miss an important email because it got catergorized as spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "2. In what order did you complete the steps?\n",
    "3. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "4. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "1.\n",
    "I mostly used the example jupyter notebooks, and googled whenever I got confused, or lost. The website I used the most, when I was lost, was geeksforgeeks.com or scikit-learn.com, as they have very good resources for learning.\n",
    "\n",
    "2. \n",
    "I did everythign in the steps that they were written. Data input and procerssing then training and validating models and finally visualizing.\n",
    "\n",
    "3.\n",
    "I did not use generative AI, as I don't learn much by using it.\n",
    "\n",
    "4.\n",
    "I was confused during the validation process, as I had assumed I was meant to use Cross-Validation however I soon learned from peers that was wrong. However I still did not understand why the training and validation scores for the 2-column data set were so much higher using cross-validation compared to the method that I did end up using."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X (1030, 8)\n",
      "Type of X <class 'pandas.core.frame.DataFrame'>\n",
      "Size of y (1030,)\n",
      "Type of y <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "\n",
    "X,y = load_concrete()\n",
    "# TO DO: Print size and type of X and y\n",
    "print(\"Size of X\",X.shape)\n",
    "print(\"Type of X\", type(X))\n",
    "print(\"Size of y\", y.shape)\n",
    "print(\"Type of y\", type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "missing = np.isnan(X).sum().sum()\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b5041945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "y_val_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "970c038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training data's R^2 score is 0.594\n",
      "The Training data's mean squared error is 110.945\n",
      "The Validation data's R^2 score is 0.672\n",
      "The Validation data's mean squared error is 96.631\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "val_r2 = r2_score(y_test,y_val_pred)\n",
    "val_mse = mean_squared_error(y_test,y_val_pred)\n",
    "\n",
    "train_r2 = r2_score(y_train,y_train_pred)  \n",
    "train_mse = mean_squared_error(y_train,y_train_pred)\n",
    "\n",
    "\n",
    "print(\"The Training data's R^2 score is {:.3f}\".format(train_r2))\n",
    "print(\"The Training data's mean squared error is {:.3f}\".format(train_mse))\n",
    "\n",
    "print(\"The Validation data's R^2 score is {:.3f}\".format(val_r2))\n",
    "print(\"The Validation data's mean squared error is {:.3f}\".format(val_mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Training Accuracy Validation Accuracy\n",
      "Mean Squared Error        110.945138           96.631335\n",
      "R2 Score                    0.594377            0.671732\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "results = pd.DataFrame(columns=['Training Accuracy', 'Validation Accuracy'],index=['Mean Squared Error','R2 Score'])\n",
    "\n",
    "results.at['Mean Squared Error','Training Accuracy'] = train_mse\n",
    "results.at['R2 Score','Training Accuracy'] = train_r2\n",
    "results.at['Mean Squared Error','Validation Accuracy'] = val_mse\n",
    "results.at['R2 Score','Validation Accuracy'] = val_r2\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "\n",
    "The linear model created produced alright results, the model does not completely fail but it does not preform well, the accuracy is not the best and the variance between the training and validation accuracy is around 4% which shows some bias and variance but it is not too high. I would not say that this is a good result mainly because of the low R2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "2. In what order did you complete the steps?\n",
    "3. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "4. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "1. \n",
    "I got my code and methodology from the lecture notes and the example jupyter notebooks \n",
    "\n",
    "2.\n",
    "I did the steps in the general order of data collection and processing then model training and validation and then finally visualization\n",
    "\n",
    "3.\n",
    "I did not use generative AI \n",
    "\n",
    "4.\n",
    "I was not challanged by this part, however I was confused by what was meant by getting the training and validation accuracy from R2 and MSE, as I thought there was an accuracy score that could be derived by them, there is not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "The pattern I noticed is the fact that more data results in better accuracy and higher bias, when there is less data there is higher variance, and when there are less parameters (columns) there is lowered accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "I really liked learning about how to do proper validation for binary classification models, however this led to some confusion about how to do that validation. Having so many variables make the code harder to track, especially since I commited to a confusing looking naming convention. I found the linear regression bit motivating becuase I realized I could do it easily compared to the binary classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b9e94f",
   "metadata": {},
   "source": [
    "### Ridge and Lasso Regresson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "47623d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso accuracy results:\n",
      "                   Training Accuracy Validation Accuracy\n",
      "Mean Squared Error        105.381711          114.753285\n",
      "R2 Score                    0.635541            0.537013\n",
      "\n",
      "Ridge accuracy results:\n",
      "                   Training Accuracy Validation Accuracy\n",
      "Mean Squared Error        105.381711          114.752904\n",
      "R2 Score                    0.635541            0.537015\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "X,y = load_concrete()\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "ridge_model = Ridge(alpha=0.001)\n",
    "ridge_model.fit(X_train,y_train)\n",
    "ridge_val_pred = ridge_model.predict(X_test)\n",
    "ridge_train_pred = ridge_model.predict(X_train)\n",
    "\n",
    "lasso_model = Lasso(alpha=0.001)\n",
    "lasso_model.fit(X_train,y_train)\n",
    "lasso_val_pred = lasso_model.predict(X_test)\n",
    "lasso_train_pred = lasso_model.predict(X_train)\n",
    "\n",
    "ridge_val_r2 = r2_score(y_test,ridge_val_pred)\n",
    "ridge_val_mse = mean_squared_error(y_test,ridge_val_pred)\n",
    "ridge_train_r2 = r2_score(y_train,ridge_train_pred)  \n",
    "ridge_train_mse = mean_squared_error(y_train,ridge_train_pred)\n",
    "\n",
    "lasso_val_r2 = r2_score(y_test,lasso_val_pred)\n",
    "lasso_val_mse = mean_squared_error(y_test,lasso_val_pred)\n",
    "lasso_train_r2 = r2_score(y_train,lasso_train_pred)  \n",
    "lasso_train_mse = mean_squared_error(y_train,lasso_train_pred)\n",
    "\n",
    "ridgeResults = pd.DataFrame(columns=['Training Accuracy', 'Validation Accuracy'],index=['Mean Squared Error','R2 Score'])\n",
    "\n",
    "ridgeResults.at['Mean Squared Error','Training Accuracy'] = ridge_train_mse\n",
    "ridgeResults.at['R2 Score','Training Accuracy'] = ridge_train_r2\n",
    "ridgeResults.at['Mean Squared Error','Validation Accuracy'] = ridge_val_mse\n",
    "ridgeResults.at['R2 Score','Validation Accuracy'] = ridge_val_r2\n",
    "\n",
    "lassoResults = pd.DataFrame(columns=['Training Accuracy', 'Validation Accuracy'],index=['Mean Squared Error','R2 Score'])\n",
    "\n",
    "lassoResults.at['Mean Squared Error','Training Accuracy'] = lasso_train_mse\n",
    "lassoResults.at['R2 Score','Training Accuracy'] = lasso_train_r2\n",
    "lassoResults.at['Mean Squared Error','Validation Accuracy'] = lasso_val_mse\n",
    "lassoResults.at['R2 Score','Validation Accuracy'] = lasso_val_r2\n",
    "\n",
    "print(\"Lasso accuracy results:\")\n",
    "print(lassoResults)\n",
    "print(\"\\nRidge accuracy results:\")\n",
    "print(ridgeResults)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    "Alpha in both Lasso and Ridge will determine how much the L1 or L2 regularization will effect the model. For lasso it will be L1 regularization, if the alpha is zero the model will be the same as Linear Regression, and a higher alpha means the model will apply L1 regularization more aggressively. Ridge Regression uses L2 regularization, meaning when alpha is zero the model will be the same as Linear Regression, and a higher alpha means the model will apply L2 regularization more aggressively, until all the coefficients become zero."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
